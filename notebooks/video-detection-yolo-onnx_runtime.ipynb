{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T21:34:10.693844Z",
     "iopub.status.busy": "2024-08-08T21:34:10.693391Z",
     "iopub.status.idle": "2024-08-08T21:34:12.136194Z",
     "shell.execute_reply": "2024-08-08T21:34:12.134007Z",
     "shell.execute_reply.started": "2024-08-08T21:34:10.693808Z"
    }
   },
   "source": [
    "<img src=\"https://github.com/RadimKozl/OpenCV_Project4/blob/832738cf629a0d6518297f860fd1952e3eaa3143/notebooks/img/OpenCV_logo.png\" alt=\"OpenCV logo\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Video Face Mask Detection***\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Import libraries***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "import pickle, cv2, sys, os, csv\n",
    "\n",
    "from sys import exit\n",
    "\n",
    "from dataPath import MODEL_PATH, VIDEOS_PATH, PICKLE_PATH, DATA_PATH\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import onnxruntime as ort\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, IntSlider, Output\n",
    "from ipywidgets.widgets.interaction import interactive\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Load models***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model_dir = os.path.join(MODEL_PATH, 'onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path_dir, suffix='.onnx'):\n",
    "    list_files = os.listdir(path_dir)\n",
    "    list_models_files = [file for file in list_files if os.path.isfile(os.path.join(path_dir, file)) and file.endswith(suffix)]\n",
    "    return list_models_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YOLOv10m_FMD_01.onnx',\n",
       " 'YOLOv10m_FMD_02.onnx',\n",
       " 'YOLOv5m_FMD.onnx',\n",
       " 'YOLOv6m_FMD_01.onnx',\n",
       " 'YOLOv6m_FMD_02.onnx',\n",
       " 'YOLOv7_FMD_01.onnx',\n",
       " 'YOLOv7_FMD_02.onnx',\n",
       " 'YOLOv7_FMD_03.onnx',\n",
       " 'YOLOv8m_FMD.onnx',\n",
       " 'YOLOv9m_FMD.onnx']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_names = load_file(path_model_dir, suffix='.onnx')\n",
    "models_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(DATA_PATH, 'pickle')):\n",
    "    os.mkdir(os.path.join(DATA_PATH, 'pickle')) \n",
    "    \n",
    "PICKLE_PATH = os.path.join(DATA_PATH, 'pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sel_model(name):\n",
    "    path = os.path.join(path_model_dir,name)\n",
    "    data = (name, path)\n",
    "    file_path = os.path.join(PICKLE_PATH, 'sel_video_model.pkl')\n",
    "    with open(file_path, 'wb') as f:  \n",
    "        pickle.dump(data, f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "995617db127447e2a03008e8d82f6120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='name', options=('YOLOv10m_FMD_01.onnx', 'YOLOv10m_FMD_02.onnx', 'Y…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_model = interact(sel_model, name=models_names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PICKLE_PATH, 'sel_video_model.pkl'), 'rb') as f:\n",
    "    sel_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Create model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_session = ort.InferenceSession(sel_model[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input name:  images \n",
      "Output names:  ['output0']\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "input_name = model_session.get_inputs()[0].name\n",
    "output_names = [output.name for output in model_session.get_outputs()]\n",
    "print(\n",
    "    'Input name: ', input_name,\n",
    "    '\\nOutput names: ', output_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  [1, 3, 640, 640] \n",
      "Output shape:  [[1, 6, 8400]]\n"
     ]
    }
   ],
   "source": [
    "input_shape = model_session.get_inputs()[0].shape\n",
    "output_shape = [output.shape for output in model_session.get_outputs()]\n",
    "print(\n",
    "    'Input shape: ', input_shape,\n",
    "    '\\nOutput shape: ', output_shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose_check_output = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transpose is necessary:  False\n"
     ]
    }
   ],
   "source": [
    "# check models\n",
    "if len(output_shape[0]) != 3:\n",
    "    print('Wrong type of model used!!!')\n",
    "    assert len(output_shape[0]) == 3\n",
    "    \n",
    "else:\n",
    "    if output_shape[0][1] > output_shape[0][2]:\n",
    "        transpose_check_output = False\n",
    "    else:\n",
    "        transpose_check_output = False\n",
    "\n",
    "print('Transpose is necessary: ', transpose_check_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Load videos***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir_videos = os.path.join(VIDEOS_PATH, 'test_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test-video1.mp4', 'test-video2.mp4']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_names = load_file(path_dir_videos, suffix='.mp4')\n",
    "videos_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sel_video(name):\n",
    "    path = os.path.join(path_dir_videos,name)\n",
    "    data = (name, path)\n",
    "    file_path = os.path.join(PICKLE_PATH, 'selected_video.pkl')\n",
    "    with open(file_path, 'wb') as f:  \n",
    "        pickle.dump(data, f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d0ed4c6a5449b5a39125bd5af13500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='name', options=('test-video1.mp4', 'test-video2.mp4'), value='test…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_video = interact(sel_video, name=videos_names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PICKLE_PATH, 'selected_video.pkl'), 'rb') as f:\n",
    "    sel_video = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(VIDEOS_PATH,'results')):\n",
    "    os.mkdir(os.path.join(VIDEOS_PATH,'results')) \n",
    "    \n",
    "PATH_RESULTS = os.path.join(VIDEOS_PATH,'results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the video\n",
    "cap = cv2.VideoCapture(sel_video[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnxruntime_YOLOv9m_FMD_test-video2.mp4\n"
     ]
    }
   ],
   "source": [
    "# Set output for video\n",
    "name_used_model = sel_model[0].split('.')[0]\n",
    "name_result_video = 'onnxruntime_' + name_used_model + '_' + sel_video[0]\n",
    "print(name_result_video)\n",
    "output_path = os.path.join(PATH_RESULTS, name_result_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set codec and videowriter\n",
    "#fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for image processing\n",
    "input_width = 640\n",
    "input_height = 640\n",
    "conf_threshold = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Video processing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define YOLO classes, form YAML file of train process\n",
    "yolo_classes = ['mask','no-mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a color map for different classes\n",
    "COLOR_MAP = {\n",
    "    'mask': (0, 255, 0),  # Green for class 0 (mask)\n",
    "    'no-mask': (0, 0, 255)  # Red for class 1 (no-mask)\n",
    "    # Add more classes and colors as needed\n",
    "}\n",
    "\n",
    "# Set the font size\n",
    "FONT_TYPE = cv2.FONT_HERSHEY_SIMPLEX\n",
    "THICKNESS = 2\n",
    "SCALE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot detections on an image\n",
    "def draw_boxes(frame, boxes):\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2, class_label, prob = box\n",
    "        #print(x1, y1, x2, y2, class_label, prob)\n",
    "        label = f\"Class {class_label}: {prob:.2f}\"\n",
    "        color = COLOR_MAP[class_label]\n",
    "        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, THICKNESS) \n",
    "        cv2.putText(frame, label, (int(x1), int(y1) - 10), FONT_TYPE, fontScale=SCALE, color=color, thickness=THICKNESS)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the area of ​​intersection\n",
    "def intersection(box1,box2):\n",
    "    box1_x1,box1_y1,box1_x2,box1_y2 = box1[:4]\n",
    "    box2_x1,box2_y1,box2_x2,box2_y2 = box2[:4]\n",
    "    x1 = max(box1_x1,box2_x1)\n",
    "    y1 = max(box1_y1,box2_y1)\n",
    "    x2 = min(box1_x2,box2_x2)\n",
    "    y2 = min(box1_y2,box2_y2)\n",
    "    return (x2-x1)*(y2-y1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the connection area\n",
    "def union(box1,box2):\n",
    "    box1_x1,box1_y1,box1_x2,box1_y2 = box1[:4]\n",
    "    box2_x1,box2_y1,box2_x2,box2_y2 = box2[:4]\n",
    "    box1_area = (box1_x2-box1_x1)*(box1_y2-box1_y1)\n",
    "    box2_area = (box2_x2-box2_x1)*(box2_y2-box2_y1)\n",
    "    return box1_area + box2_area - intersection(box1,box2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide one by the other\n",
    "def iou(box1,box2):\n",
    "    return intersection(box1,box2)/union(box1,box2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess image\n",
    "def preprocess(image):\n",
    "    img = cv2.resize(image, (input_width, input_height))\n",
    "    img = img.transpose(2, 0, 1)  # Convert to format (channels, height, width)\n",
    "    img = img[np.newaxis, :, :, :].astype(np.float32) / 255.0  # Normalize and add dimension\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_row(row, img_width, img_height, class_names):\n",
    "    # slice out tx_center, y_center, width, height from the row\n",
    "    xc,yc,w,h = row[:4]\n",
    "\n",
    "    # calculate coordinates of bounding box corners\n",
    "    x1 = (xc-w/2)/640*img_width\n",
    "    y1 = (yc-h/2)/640*img_height\n",
    "    x2 = (xc+w/2)/640*img_width\n",
    "    y2 = (yc+h/2)/640*img_height\n",
    "\n",
    "    # find the object with a maximum probability\n",
    "    prob = row[4:].max()\n",
    "    # id of class\n",
    "    class_id = row[4:].argmax()\n",
    "\n",
    "    # Check class annotation, note: YOLOv7 have different annotation 1,2 not 0,1!!!\n",
    "    if (len(class_names)-1) < class_id:\n",
    "        # get a class label by ID\n",
    "        label = class_names[(class_id-1)]\n",
    "    else:\n",
    "        # get a class label by ID\n",
    "        label = class_names[class_id]\n",
    "\n",
    "    return [x1, y1, x2, y2, label, prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(frame, outputs, class_labels, conf_threshold, iou_threshold):\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    #boxes, scores, class_labels = [], [], []\n",
    "    \n",
    "    # We expect output[0] to contain detections\n",
    "    detections = outputs[0]\n",
    "\n",
    "\n",
    "    # Check Output shape\n",
    "    detections_shape = detections.shape\n",
    "        \n",
    "    # We turned it out to a matrix with 84 rows and, 8400 columns.\n",
    "    if detections_shape[1] < detections_shape[2]:\n",
    "        detections = detections.transpose(0, 2, 1)[0]\n",
    "        #print('Turned output shape: ', output.shape)\n",
    "    else:\n",
    "        detections = detections[0]\n",
    "\n",
    "    # parses and filter outs all rows from output\n",
    "    boxes = [row for row in [parse_row(row, frame_width, frame_height, class_labels) for row in detections] if row[5] > conf_threshold]\n",
    "    boxes.sort(key=lambda x: x[5], reverse=True)\n",
    "\n",
    "    filtered_boxes = []\n",
    "    while len(boxes)>0:\n",
    "        filtered_boxes.append(boxes[0])\n",
    "        boxes = [box for box in boxes if iou(box,boxes[0])<iou_threshold]\n",
    "    \n",
    "    return filtered_boxes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_conf_threshold(conf_threshold):\n",
    "    file_path = os.path.join(PICKLE_PATH, 'conf_threshold_video.pkl')\n",
    "    with open(file_path, 'wb') as f:  \n",
    "        pickle.dump(round(conf_threshold, 2), f)\n",
    "    return conf_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4c8873e68048efbb0081855a5b3f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='conf_threshold', max=1.0, min=0.1, step=0.01), Outpu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(check_conf_threshold, conf_threshold=widgets.FloatSlider(min=0.1, max=1.0, step=0.01, value=0.50));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(PICKLE_PATH, 'conf_threshold_video.pkl'), 'rb') as f:\n",
    "    conf_threshold = pickle.load(f)\n",
    "\n",
    "print(conf_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_iou_threshold(iou_threshold):\n",
    "    file_path = os.path.join(PICKLE_PATH, 'iou_threshold_video.pkl')\n",
    "    with open(file_path, 'wb') as f:  \n",
    "        pickle.dump(round(iou_threshold, 2), f)\n",
    "    return iou_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7636f4fc8944a14a9f19d3cebcac1fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.7, description='iou_threshold', max=1.0, min=0.1, step=0.01), Output…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(check_iou_threshold, iou_threshold=widgets.FloatSlider(min=0.1, max=1.0, step=0.01, value=0.70));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(PICKLE_PATH, 'iou_threshold_video.pkl'), 'rb') as f:\n",
    "    iou_threshold = pickle.load(f)\n",
    "\n",
    "print(iou_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    blob = preprocess(frame)\n",
    "\n",
    "    # Run inference\n",
    "    outputs = model_session.run(output_names, {input_name: blob})\n",
    "\n",
    "    boxes = postprocess(frame, outputs, yolo_classes, conf_threshold, iou_threshold)\n",
    "    \n",
    "    # Display of detections on the image\n",
    "    frame = draw_boxes(frame, boxes)\n",
    "    \n",
    "    out.write(frame)\n",
    "    #cv2.imshow('Video', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5418979,
     "sourceId": 8996440,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 100166,
     "modelInstanceId": 75445,
     "sourceId": 89963,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
